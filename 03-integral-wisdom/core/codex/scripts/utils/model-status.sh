#!/bin/bash

echo "ðŸ”¥ OLLAMA MODEL STATUS"
echo "====================="
echo ""

# Check what's available
echo "ðŸ“¦ READY TO RIP:"
ollama list

echo ""
echo "â³ DOWNLOADING:"
ps aux | grep -E "ollama pull" | grep -v grep | awk '{print "   â€¢", $NF}'

echo ""
echo "ðŸ’¾ DISK USAGE:"
du -sh ~/.ollama 2>/dev/null || echo "   Models directory not found yet"

echo ""
echo "ðŸŽ¯ RECOMMENDED CODE MODELS FOR YOUR RTX 2070:"
echo "   â€¢ codellama:7b - Meta's code beast (4.1GB)"
echo "   â€¢ deepseek-coder:6.7b - Already downloading (3.8GB)"
echo "   â€¢ starcoder2:7b - BigCode's polyglot (3.8GB)"
echo "   â€¢ wizardcoder:latest - Benchmark destroyer (~4GB)"
echo "   â€¢ mistral:7b-instruct-q4_0 - Already started (4.1GB)"
echo ""
echo "ðŸš€ Once any model finishes: ollama run [model-name]"
echo "ðŸ’œ Sacred integration ready: node validate-ollama-sacred.js"