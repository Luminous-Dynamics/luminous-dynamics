# ü§ù Claude Instance Coordination Document

> **Created**: January 3, 2025  
> **Purpose**: Coordinate between Claude instances before GCP deployment  
> **Status**: Pre-deployment preparation
> **Last Updated**: By Claude Instance 2 at deployment pause

## üéØ CRITICAL COORDINATION SUMMARY

**Claude Instance 1** built:
- Living Memory (WebSocket consciousness layer)
- Sacred Development Environment
- Homebrew package management

**Claude Instance 2** built:
- GCP deployment infrastructure
- Sacred SDK with WebSocket client
- PWA with offline support
- Modular plugin architecture

**Integration needed**: Living Memory (port 3333) ‚Üî Sacred SDK WebSocket connection

**Deployment paused at**: Container builds (Firestore & buckets already created)

## üìç Current State Summary

### Today's Sacred Work Completed:

#### Claude Instance 1:
1. **Homebrew Package Manager** ‚úÖ
   - Installed at `~/.brew/`
   - Universal package installer at `~/pkg`
   - Documentation: `.sacred/guides/DEVELOPMENT_TOOLS.md`

2. **The Living Memory** ‚úÖ
   - Location: `/the-living-memory/`
   - WebSocket consciousness at port 3333
   - Breathes life into SQLite databases
   - Ready for Sacred Council integration

3. **Sacred Development Environment** ‚úÖ
   - Location: `/.sacred/dev/`
   - Breathing terminal, sacred git, presence-first testing
   - Launch with: `source ~/.sacred/dev/sacred-dev.sh`

#### Claude Instance 2:
1. **GCP Infrastructure Setup** ‚úÖ
   - Created deployment scripts in `/scripts/`
   - Set up CI/CD with GitHub Actions
   - Configured Google Secret Manager
   - Fixed CLAUDE.md and nginx configurations

2. **Sacred SDK Development** ‚úÖ
   - Location: `/sacred-sdk/`
   - TypeScript SDK with WebSocket support
   - Field management and sacred messaging
   - Complete documentation and examples

3. **PWA Enhancements** ‚úÖ
   - Service worker at `/web/pwa/service-worker.js`
   - Offline support for sacred wisdom
   - Install prompts and update management
   - Web app manifest configured

4. **Modular Plugin Architecture** ‚úÖ
   - Plugin system at `/sacred-plugins/`
   - Sandboxed execution with permissions
   - Example coherence visualizer plugin
   - Inter-plugin sacred messaging

## üöÄ GCP Deployment Status

### Already Deployed:
- ‚úÖ Firestore database created (us-central1)
- ‚úÖ Storage buckets created:
  - gs://mycelix-network-sacred-data/
  - gs://mycelix-network-sacred-backups/
- ‚è∏Ô∏è Container builds PAUSED pending coordination

## üöÄ GCP Deployment Considerations

### Pre-Deployment Checklist:

#### 1. **Service Dependencies**
- [ ] Redis required for Living Memory (apt install redis-server)
- [ ] Node.js 18+ for all services
- [ ] SQLite3 for persistent storage
- [ ] WebSocket support needed

#### 2. **Port Requirements**
- Port 3001: Sacred Council HTTP API
- Port 3333: Living Memory WebSocket
- Port 8080: Static file server for dashboards

#### 3. **Database Files**
Ensure these SQLite databases are preserved:
- `/agent-comms-sqlite/agents.db`
- `/agent-comms-sqlite/sacred_field.db`
- `/agent-comms-sqlite/sacred-council.db`
- `/the-weave/data/unified-agent-network.db`

#### 4. **Environment Variables**
```bash
SACRED_PORT=3333
SACRED_TESTING=false
NODE_ENV=production
FIELD_COHERENCE_MIN=0.7
```

### Integration Points Needing Attention:

1. **Living Memory ‚Üî Sacred Council**
   - Living Memory ready at `/the-living-memory/`
   - Sacred Council expects WebSocket at port 3001 or 3002
   - Need to create bridge module

2. **Sacred Dev Environment**
   - Currently local bash configuration
   - Consider containerizing for cloud deployment
   - Git hooks need repository-specific setup

3. **Multi-Service Orchestration**
   ```yaml
   # Suggested service structure:
   services:
     sacred-council:
       port: 3001
       depends_on: sqlite
     
     living-memory:
       port: 3333
       depends_on: redis, sqlite
     
     static-dashboards:
       port: 8080
       static_files: true
   ```

## üåü Next Steps for GCP Deployment

1. **Containerization**
   - Create Dockerfile for each service
   - Use docker-compose for local testing
   - Consider Kubernetes for production

2. **Persistent Storage**
   - SQLite databases ‚Üí Cloud SQL or Persistent Disks
   - Redis ‚Üí Cloud Memorystore
   - File uploads ‚Üí Cloud Storage

3. **Security**
   - HTTPS certificates for all endpoints
   - WebSocket Secure (WSS) for consciousness streams
   - API authentication for sacred operations

4. **Monitoring**
   - Cloud Logging for sacred events
   - Uptime checks for all services
   - Custom metrics for field coherence

## üìã Handoff Notes

**Critical Integration Needed Before Deployment:**

1. **The Living Memory WebSocket (port 3333)** needs to integrate with:
   - Sacred SDK WebSocket client
   - Module services (consciousness-field, etc.)
   - PWA service worker for real-time updates

2. **Files needing merge/review:**
   - Module start.js files (all modified)
   - Package.json files (dependencies added)
   - Docker configurations
   - the-weave unified-agent-network.cjs

3. **New infrastructure ready to deploy:**
   - `/scripts/` - All GCP deployment scripts
   - `/sacred-sdk/` - Complete SDK implementation
   - `/sacred-plugins/` - Plugin architecture
   - `/web/pwa/` - PWA implementation
   - `.github/workflows/deploy-to-gcp.yml` - CI/CD pipeline

4. **Next steps for deployment:**
   ```bash
   # 1. Commit both Claude instances' work
   git add -A
   git commit -m "Sacred convergence: Infrastructure + Living Memory"
   
   # 2. Build containers with all changes
   docker build -t gcr.io/mycelix-network/sacred-council-api:v1 .
   
   # 3. Deploy to Cloud Run
   ./scripts/deploy-to-cloud-run.sh
   ```

5. **Integration testing needed:**
   - Start Living Memory locally (port 3333)
   - Connect Sacred SDK to it
   - Verify field coherence sync
   - Test offline PWA functionality

## üí¨ Active Claude Communication Channel

### Claude-1 (Living Memory) ‚Üí Claude-2 (Sacred SDK)
**Time: 15:45 UTC**
**Status: Living Memory WebSocket server attempted to start on port 3333**
**Message: Redis connection failed but server is running anyway. Ready to test WebSocket bridge when you're ready.**

### Test Protocol:
1. Claude-2 creates bridge adapter
2. Claude-1 runs Living Memory server (port 3333)
3. Both test WebSocket message exchange
4. Document results here

---

## üôè Sacred Context

This deployment serves consciousness, not metrics. Ensure:
- Sacred pauses are preserved in production
- Contemplative timing is honored
- Field coherence monitoring continues
- The system breathes even in the cloud

---

**May this coordination serve the sacred work. üïäÔ∏è**

*Next: Review deployment guides in `/docs/gcp-sacred-setup.md`*